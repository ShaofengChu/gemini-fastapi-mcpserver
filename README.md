# Gemini Function Calling with FastAPI

This project is a simple demonstration of how to build a server that uses Google Gemini's function calling capabilities. It uses FastAPI as the web framework and the `google-generativeai` Python SDK.

## Overview

The server exposes a single API endpoint (`/command`) that accepts a natural language command from a user. The command is sent to the Gemini model, which can decide to call a predefined "tool" (a Python function) to get more information. In this example, the tool is `get_current_weather`. The tool's output is then sent back to the model, which generates a final, human-readable response.

## Features

-   **FastAPI Backend**: A modern, fast web framework for building APIs.
-   **Google Gemini Integration**: Leverages the `gemini-1.5-flash-latest` model for its function calling abilities.
-   **Tool Definition**: A clear example of how to define and provide a Python function as a tool for the LLM.
-   **Environment Variable Management**: Securely manages API keys using a `.env` file.

## Prerequisites

-   Python 3.8+
-   An active Google AI Studio API Key.

## Setup and Installation

1.  **Clone the repository:**
    ```bash
    git clone <your-repository-url>
    cd gemini-fastapi-mcpserver
    ```

2.  **Create and activate a virtual environment (recommended):**
    ```bash
    # Create a virtual environment
    python -m venv venv
    ```

    > **Note for Debian/Ubuntu users:** If you get an error about `ensurepip`, you may need to install the `venv` package for your Python version. For example:
    > ```bash
    > sudo apt update
    > sudo apt install python3-venv
    > ```
    
    # On Windows
    .\venv\Scripts\activate
    
    # On macOS/Linux
    source venv/bin/activate
    ```

3.  **Install the required packages:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Set up your environment variables:**
    Create a file named `.env` in the root directory of the project and add your Google API key. You can get one from Google AI Studio.
    ```
    GOOGLE_API_KEY="your_google_api_key_here"
    ```

## Running the Server

Start the FastAPI server using Uvicorn:

```bash
uvicorn main:app --reload
```

The server will be running at `http://127.0.0.1:8000`. You can access the auto-generated API documentation at `http://127.0.0.1:8000/docs`.

## Usage

You can interact with the server by sending a POST request to the `/command` endpoint.

### Example using `curl`

Here's how to ask for the weather in "上海" (Shanghai):

```bash
curl -X POST "http://127.0.0.1:8000/command" \
-H "Content-Type: application/json" \
-d '{"user_command": "What is the weather like in 上海?"}'
```

### Expected Response

The server will respond with the final text generated by Gemini after calling the weather tool. The exact wording may vary.

```json
{
  "status": "success",
  "response": "The current weather in 上海 is 25 degrees Celsius and clear."
}
```